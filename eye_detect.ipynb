{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAwR2E7Ck/ciVQQoJoaxsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N3haS/rl-game-for-ocd-dyslexia/blob/main/eye_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGie96__E_7k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_data(folder):\n",
        "    data = []\n",
        "    label = []\n",
        "    for filename in os.listdir(folder):\n",
        "        sub_dir = os.path.join(folder, filename)\n",
        "        for img_name in os.listdir(sub_dir):\n",
        "            img_dir = os.path.join(sub_dir, img_name)\n",
        "            img = cv2.imread(img_dir)\n",
        "            # Resize image\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            # Convert to grayscale if necessary\n",
        "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            data.append(img / 255.0)  # Normalize pixel values\n",
        "            label.append(int(filename))\n",
        "    return np.array(data), np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_CNN(X_train, y_train):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(5)  # Adjust output size based on the number of classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_split=0.2)\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "NvQ0CohoFAd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_history_graph(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "8Yf8RalZFKam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = preprocess_data('eye dataset')"
      ],
      "metadata": {
        "id": "KE472KN6FMkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5c6c324e-1c83-4409-b51d-40c025b07247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'eye dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e08b01031c93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eye dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-dd9db1b0ddb9>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msub_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eye dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "data_resampled, label_resampled = smote.fit_resample(data.reshape(-1, 128*128*3), label)"
      ],
      "metadata": {
        "id": "XmHFDXbsGAXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_resampled = data_resampled.reshape(-1, 128, 128, 3)"
      ],
      "metadata": {
        "id": "aD3BA5sKGFkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_resampled, label_resampled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h0VzJPULGHpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN, history = train_CNN(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H84yG4wPGLBn",
        "outputId": "4755e0bd-e206-48fc-f5e6-02314de4b2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 8s 957ms/step - loss: 1.8411 - accuracy: 0.2190 - val_loss: 1.1340 - val_accuracy: 0.7407\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 3s 844ms/step - loss: 1.0542 - accuracy: 0.5524 - val_loss: 0.8426 - val_accuracy: 0.4815\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.7234 - accuracy: 0.6762 - val_loss: 0.5352 - val_accuracy: 0.8889\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.3074 - accuracy: 0.9619 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0915 - val_accuracy: 0.9630\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 3s 690ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0515 - val_accuracy: 0.9630\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 4s 939ms/step - loss: 0.0579 - accuracy: 0.9905 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 3s 691ms/step - loss: 0.1421 - accuracy: 0.9524 - val_loss: 0.0868 - val_accuracy: 0.9630\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 3s 688ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 3s 717ms/step - loss: 0.0986 - accuracy: 0.9714 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 4s 916ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 4s 770ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.0098 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 4s 984ms/step - loss: 7.0498e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 9.2038e-04 - accuracy: 1.0000 - val_loss: 8.9680e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 4.7196e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 3s 718ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 4s 992ms/step - loss: 4.3520e-04 - accuracy: 1.0000 - val_loss: 6.1657e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history_graph(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "HAMnz94wGW3D",
        "outputId": "0e7377d8-0017-42e2-8257-e1a5daae658d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_CNN.evaluate(X_test, y_test)\n",
        "print(\"Testing Accuracy:\", test_acc)\n",
        "print(\"Testing Loss:\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuQjxPr-Gtyw",
        "outputId": "b0abc2ce-c9d1-448a-f930-1751edaf0e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 27ms/step - loss: 4.8608e-04 - accuracy: 1.0000\n",
            "Testing Accuracy: 1.0\n",
            "Testing Loss: 0.00048607823555357754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.save('eye_movement_trained.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i60I9YkEGwMS",
        "outputId": "5ce6867c-d3b0-465c-836e-fe1ad36a0604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSRHpe_OHNSS",
        "outputId": "3d55c85b-02a3-4385-8ca8-0f020208f9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m745.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.25.2)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56441 sha256=73a2d2a04b8fa5ec80003755629e2abac9048c07dd6923215c797b6493932e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mH1I8n9HRZ3",
        "outputId": "0f0fe1cd-ceaf-498d-f25e-f703cc5c9819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import np_utils\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras import  layers, models\n",
        "import datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rpjXKfDbG5U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def show_history_graph(history):\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qatn3BpJHUC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2=[]\n",
        "data=[]\n",
        "featurematrix=[]\n",
        "label=[]\n",
        "label2=[]\n",
        "folder = \"eye dataset\"\n",
        "for filename in os.listdir(folder):\n",
        "\n",
        "    sub_dir=(folder+'/' +filename)\n",
        "    for img_name in os.listdir(sub_dir):\n",
        "        img_dir=str(sub_dir+ '/' +img_name)\n",
        "        print(int(filename),img_dir)\n",
        "        img = cv2.imread(img_dir)\n",
        "        # Resize image\n",
        "        img = cv2.resize(img,(128,128))\n",
        "        if len(img.shape)==3:\n",
        "            img2 = cv2.resize(img,(32,32))\n",
        "            img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "            img2=img2.flatten()\n",
        "            data2.append(img2/255.0)\n",
        "            label2.append(int(filename))\n",
        "\n",
        "        data11=np.array(img)\n",
        "        data.append(data11/255.0)\n",
        "        label.append(int(filename))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnaOvvFGHtaB",
        "outputId": "18ba25cc-ce0a-46bd-e495-3e4bc224bd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 eye dataset/1/38.jpg\n",
            "1 eye dataset/1/35.jpg\n",
            "1 eye dataset/1/101.jpg\n",
            "1 eye dataset/1/39.jpg\n",
            "1 eye dataset/1/102.jpg\n",
            "1 eye dataset/1/107.jpg\n",
            "1 eye dataset/1/33.jpg\n",
            "1 eye dataset/1/29.jpg\n",
            "1 eye dataset/1/108.jpg\n",
            "1 eye dataset/1/106.jpg\n",
            "1 eye dataset/1/103.jpg\n",
            "1 eye dataset/1/31.jpg\n",
            "1 eye dataset/1/110.jpg\n",
            "1 eye dataset/1/105.jpg\n",
            "1 eye dataset/1/32.jpg\n",
            "1 eye dataset/1/37.jpg\n",
            "1 eye dataset/1/36.jpg\n",
            "1 eye dataset/1/34.jpg\n",
            "1 eye dataset/1/104.jpg\n",
            "1 eye dataset/1/109.jpg\n",
            "1 eye dataset/1/30.jpg\n",
            "1 eye dataset/1/40.jpg\n",
            "0 eye dataset/0/120.jpg\n",
            "0 eye dataset/0/10.jpg\n",
            "0 eye dataset/0/171.jpg\n",
            "0 eye dataset/0/27.jpg\n",
            "0 eye dataset/0/9.jpg\n",
            "0 eye dataset/0/19.jpg\n",
            "0 eye dataset/0/173.jpg\n",
            "0 eye dataset/0/6.jpg\n",
            "0 eye dataset/0/165.jpg\n",
            "0 eye dataset/0/21.jpg\n",
            "0 eye dataset/0/17.jpg\n",
            "0 eye dataset/0/184.jpg\n",
            "0 eye dataset/0/179.jpg\n",
            "0 eye dataset/0/169.jpg\n",
            "0 eye dataset/0/182.jpg\n",
            "0 eye dataset/0/166.jpg\n",
            "0 eye dataset/0/15.jpg\n",
            "0 eye dataset/0/121.jpg\n",
            "0 eye dataset/0/14.jpg\n",
            "0 eye dataset/0/125.jpg\n",
            "0 eye dataset/0/26.jpg\n",
            "0 eye dataset/0/3.jpg\n",
            "0 eye dataset/0/24.jpg\n",
            "0 eye dataset/0/11.jpg\n",
            "0 eye dataset/0/183.jpg\n",
            "0 eye dataset/0/128.jpg\n",
            "0 eye dataset/0/174.jpg\n",
            "0 eye dataset/0/8.jpg\n",
            "0 eye dataset/0/185.jpg\n",
            "0 eye dataset/0/16.jpg\n",
            "0 eye dataset/0/5.jpg\n",
            "0 eye dataset/0/18.jpg\n",
            "0 eye dataset/0/172.jpg\n",
            "0 eye dataset/0/124.jpg\n",
            "0 eye dataset/0/167.jpg\n",
            "0 eye dataset/0/28.jpg\n",
            "0 eye dataset/0/12.jpg\n",
            "0 eye dataset/0/123.jpg\n",
            "0 eye dataset/0/4.jpg\n",
            "0 eye dataset/0/126.jpg\n",
            "0 eye dataset/0/23.jpg\n",
            "0 eye dataset/0/170.jpg\n",
            "0 eye dataset/0/178.jpg\n",
            "0 eye dataset/0/180.jpg\n",
            "0 eye dataset/0/181.jpg\n",
            "0 eye dataset/0/13.jpg\n",
            "0 eye dataset/0/2.jpg\n",
            "0 eye dataset/0/119.jpg\n",
            "0 eye dataset/0/1.jpg\n",
            "0 eye dataset/0/7.jpg\n",
            "0 eye dataset/0/25.jpg\n",
            "0 eye dataset/0/122.jpg\n",
            "0 eye dataset/0/20.jpg\n",
            "0 eye dataset/0/168.jpg\n",
            "0 eye dataset/0/22.jpg\n",
            "2 eye dataset/2/114.jpg\n",
            "2 eye dataset/2/256.jpg\n",
            "2 eye dataset/2/111.jpg\n",
            "2 eye dataset/2/46.jpg\n",
            "2 eye dataset/2/257.jpg\n",
            "2 eye dataset/2/48.jpg\n",
            "2 eye dataset/2/50.jpg\n",
            "2 eye dataset/2/51.jpg\n",
            "2 eye dataset/2/52.jpg\n",
            "2 eye dataset/2/253.jpg\n",
            "2 eye dataset/2/261.jpg\n",
            "2 eye dataset/2/45.jpg\n",
            "2 eye dataset/2/54.jpg\n",
            "2 eye dataset/2/55.jpg\n",
            "2 eye dataset/2/60.jpg\n",
            "2 eye dataset/2/49.jpg\n",
            "2 eye dataset/2/44.jpg\n",
            "2 eye dataset/2/58.jpg\n",
            "2 eye dataset/2/258.jpg\n",
            "2 eye dataset/2/117.jpg\n",
            "2 eye dataset/2/53.jpg\n",
            "2 eye dataset/2/249.jpg\n",
            "2 eye dataset/2/255.jpg\n",
            "2 eye dataset/2/118.jpg\n",
            "2 eye dataset/2/47.jpg\n",
            "2 eye dataset/2/248.jpg\n",
            "2 eye dataset/2/260.jpg\n",
            "2 eye dataset/2/57.jpg\n",
            "2 eye dataset/2/251.jpg\n",
            "2 eye dataset/2/113.jpg\n",
            "2 eye dataset/2/43.jpg\n",
            "2 eye dataset/2/112.jpg\n",
            "2 eye dataset/2/250.jpg\n",
            "2 eye dataset/2/59.jpg\n",
            "2 eye dataset/2/247.jpg\n",
            "2 eye dataset/2/116.jpg\n",
            "2 eye dataset/2/56.jpg\n",
            "2 eye dataset/2/252.jpg\n",
            "2 eye dataset/2/259.jpg\n",
            "2 eye dataset/2/254.jpg\n",
            "2 eye dataset/2/115.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_CNN(data, label):\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.20)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(36))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_test, Y_test))\n",
        "\n",
        "    # Show training history\n",
        "    show_history_graph(history)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
        "    print(\"Testing Accuracy is \", test_acc)\n",
        "    print(\"Testing loss is \", test_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('eye_movement_trained.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "# CNN Training\n",
        "model_CNN = train_CNN(data,label)\n",
        "Y_CNN=model_CNN.predict(np.array(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "iPJOYZ5WH5wx",
        "outputId": "c75faa2a-091a-4714-d89d-c9f0870eee03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-52b36804abe6>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# CNN Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mY_CNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def train_CNN_with_augmentation(data, label):\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.20)\n",
        "\n",
        "    # Data augmentation for both images and labels\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    # Fit data augmentation generator on training data\n",
        "    train_datagen.fit(X_train)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dense(36))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with augmented data\n",
        "    history = model.fit(train_datagen.flow(X_train, Y_train, batch_size=32),\n",
        "                        steps_per_epoch=len(X_train) / 32,\n",
        "                        epochs=20,\n",
        "                        validation_data=(X_test, Y_test))\n",
        "\n",
        "    # Show training history\n",
        "    show_history_graph(history)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
        "    print(\"Testing Accuracy is \", test_acc)\n",
        "    print(\"Testing loss is \", test_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('eye_movement_trained_with_augmentation.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "# CNN Training with Data Augmentation\n",
        "model_CNN_with_augmentation = train_CNN_with_augmentation(data, label)\n",
        "Y_CNN_with_augmentation = model_CNN_with_augmentation.predict(np.array(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "vPBpBZ2T30XX",
        "outputId": "b37bc475-4d1c-4816-a61f-d75caf5fdf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (128, 128, 3), y.shape = (94,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4799fbcb96b0>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# CNN Training with Data Augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mmodel_CNN_with_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN_with_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mY_CNN_with_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_CNN_with_augmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4799fbcb96b0>\u001b[0m in \u001b[0;36mtrain_CNN_with_augmentation\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Train the model with augmented data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     history = model.fit(train_datagen.flow(X_train, Y_train, batch_size=32),\n\u001b[0m\u001b[1;32m     42\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \"\"\"\n\u001b[0;32m-> 1545\u001b[0;31m         return NumpyArrayIterator(\n\u001b[0m\u001b[1;32m   1546\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    708\u001b[0m                 \u001b[0;34m\"`x` (images tensor) and `y` (labels) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;34m\"should have the same length. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (128, 128, 3), y.shape = (94,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "def preprocess_data(data, label):\n",
        "    # Preprocess the data (resize, normalize, etc.)\n",
        "    processed_data = np.array([img_to_array(array_to_img(img, scale=False).resize((224, 224))) / 255. for img in data])\n",
        "    processed_label = np.array(label)\n",
        "    return processed_data, label\n",
        "\n",
        "def train_CNN_with_transfer_learning(data, label):\n",
        "    # Preprocess the data\n",
        "    processed_data, label = preprocess_data(data, label)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(processed_data, label, test_size=0.20)\n",
        "\n",
        "    # Load the pre-trained VGG16 model (without the top classification layer)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze the convolutional base\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add a custom classification head\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(36, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test))\n",
        "\n",
        "    # Show training history\n",
        "    show_history_graph(history)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
        "    print(\"Testing Accuracy is \", test_acc)\n",
        "    print(\"Testing loss is \", test_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('eye_movement_trained_with_transfer_learning.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "# CNN Training with Transfer Learning\n",
        "model_CNN_with_transfer_learning = train_CNN_with_transfer_learning(data, label)\n",
        "Y_CNN_with_transfer_learning = model_CNN_with_transfer_learning.predict(np.array(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lBUI07QB4Zbv",
        "outputId": "5b6d59f5-2d4f-4f0a-83a5-cbfc1445edb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-74096a914212>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# CNN Training with Transfer Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel_CNN_with_transfer_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN_with_transfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mY_CNN_with_transfer_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_CNN_with_transfer_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-74096a914212>\u001b[0m in \u001b[0;36mtrain_CNN_with_transfer_learning\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Show training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "def preprocess_data(data, label):\n",
        "    # Preprocess the data (resize, normalize, etc.)\n",
        "    processed_data = np.array([img_to_array(array_to_img(img, scale=False).resize((224, 224))) / 255. for img in data])\n",
        "    processed_label = np.array(label)  # Convert labels to numpy array\n",
        "    return processed_data, processed_label\n",
        "\n",
        "def train_CNN_with_transfer_learning(data, label):\n",
        "    # Preprocess the data\n",
        "    processed_data, processed_label = preprocess_data(data, label)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(processed_data, processed_label, test_size=0.20)\n",
        "\n",
        "    # Load the pre-trained VGG16 model (without the top classification layer)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze the convolutional base\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add a custom classification head\n",
        "    model = keras.models.Sequential([\n",
        "        base_model,\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(36, activation='softmax')  # Assuming 36 classes\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test))\n",
        "\n",
        "    # Show training history\n",
        "    show_history_graph(history)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n",
        "    print(\"Testing Accuracy is \", test_acc)\n",
        "    print(\"Testing loss is \", test_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('eye_movement_trained_with_transfer_learning.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Convert labels to numpy array\n",
        "label = np.array(label)\n",
        "\n",
        "# CNN Training with Transfer Learning\n",
        "model_CNN_with_transfer_learning = train_CNN_with_transfer_learning(data, label)\n",
        "Y_CNN_with_transfer_learning = model_CNN_with_transfer_learning.predict(np.array(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8CSgDWs_43q9",
        "outputId": "0a8749e1-7035-40eb-d51c-c5bea99b0c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-2e8c520fa066>\", line 61, in <cell line: 61>\n\n  File \"<ipython-input-15-2e8c520fa066>\", line 42, in train_CNN_with_transfer_learning\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,36] and labels shape [1152]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_4824]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2e8c520fa066>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# CNN Training with Transfer Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mmodel_CNN_with_transfer_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN_with_transfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mY_CNN_with_transfer_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_CNN_with_transfer_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-2e8c520fa066>\u001b[0m in \u001b[0;36mtrain_CNN_with_transfer_learning\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Show training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-2e8c520fa066>\", line 61, in <cell line: 61>\n\n  File \"<ipython-input-15-2e8c520fa066>\", line 42, in train_CNN_with_transfer_learning\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,36] and labels shape [1152]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_4824]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from imutils.video import VideoStream\n",
        "import os\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "list1= ['looking at center','looking at left','looking at right','looking at up','looking at down']\n",
        "eye_cnn = tf.keras.models.load_model('eye_movement_trained.h5')\n",
        "# histogram based equalization\n",
        "def histogram_equalization(img):\n",
        "    r,g,b = cv2.split(img)\n",
        "    f_img1 = cv2.equalizeHist(r)\n",
        "    f_img2 = cv2.equalizeHist(g)\n",
        "    f_img3 = cv2.equalizeHist(b)\n",
        "    img = cv2.merge((f_img1,f_img2,f_img3))\n",
        "    return img\n",
        "\n"
      ],
      "metadata": {
        "id": "tjxW5e3sIBuS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d8991732-bc5d-4caa-a8d2-f3ccf0e0c62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at eye_movement_trained.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bdb2dd7ed68a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlist1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'looking at center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'looking at left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'looking at right'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'looking at up'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'looking at down'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0meye_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eye_movement_trained.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# histogram based equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhistogram_equalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at eye_movement_trained.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7OUuJ3lIU3j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}